{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor shape: torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvertTo3Channels(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvertTo3Channels, self).__init__()\n",
    "        self.conv = nn.Conv2d(512, 3, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1, 32, 32)\n",
    "        return self.conv(x)\n",
    "\n",
    "# Example usage\n",
    "input_tensor = torch.randn(1, 512, 32, 32)  # Example input tensor\n",
    "\n",
    "# Convert to 3 channels\n",
    "converter = ConvertTo3Channels()\n",
    "output_tensor = converter(input_tensor)\n",
    "print(\"Output tensor shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.3211, -1.1504,  0.2494,  ...,  0.1789, -0.9868, -0.7163],\n",
       "          [ 0.1738,  0.1289, -0.7453,  ..., -0.5446,  0.7256,  0.6766],\n",
       "          [ 0.1112, -0.0700, -0.1391,  ..., -1.3333,  0.7103,  1.0882],\n",
       "          ...,\n",
       "          [ 0.3553, -1.4619,  0.5232,  ..., -0.1441,  0.1739, -0.1861],\n",
       "          [ 0.6959,  1.1374, -1.2228,  ..., -0.0699,  0.3611,  0.1375],\n",
       "          [-0.3749,  0.2975,  0.2018,  ..., -0.7373,  0.1982,  0.3421]],\n",
       "\n",
       "         [[ 0.0651,  0.1019, -0.6330,  ..., -0.0850,  0.1727,  0.2022],\n",
       "          [ 0.3702, -0.3912,  0.5050,  ..., -0.0117, -0.4342,  0.2370],\n",
       "          [-0.0913, -0.2539,  0.1703,  ...,  0.4658,  0.1329, -0.0102],\n",
       "          ...,\n",
       "          [ 1.6260,  0.1773, -0.6413,  ...,  0.5294, -0.6304,  0.0364],\n",
       "          [-0.2172,  0.0373,  0.8763,  ...,  0.2222,  0.0988,  1.0310],\n",
       "          [ 0.1355, -0.2102, -0.8702,  ...,  0.2149, -0.0477,  0.7097]],\n",
       "\n",
       "         [[ 0.2472, -0.3047,  0.4292,  ...,  1.0233, -0.7907,  0.3653],\n",
       "          [-0.7131, -0.7426, -0.5686,  ..., -0.1051, -0.6066,  0.3728],\n",
       "          [ 0.0900, -0.6461, -0.0695,  ...,  0.8779,  0.4415,  0.4884],\n",
       "          ...,\n",
       "          [ 0.1274, -0.5518,  0.8686,  ...,  0.2270, -0.1493,  0.0393],\n",
       "          [ 0.2297, -0.3253, -0.6251,  ..., -0.3456,  0.0589,  1.1609],\n",
       "          [-0.0281,  0.6899, -0.6368,  ..., -0.1862, -0.4167,  0.4695]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
